<!DOCTYPE html><html><head><meta name="generator" content="Hexo 3.9.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="This is myblog!"><meta name="keywords" content><meta name="author" content="bb,shuiyue75381@gmail.com"><meta name="copyright" content="bb"><title>【bb的博客】</title><link rel="stylesheet" href="/css/fan.css"><link rel="stylesheet" href="/css/thirdparty/jquery.mCustomScrollbar.min.css"><link rel="icon" href="/favicon.ico"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.10.4/dist/instantsearch.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.10.4/dist/instantsearch-theme-algolia.min.css"><script src="https://cdn.jsdelivr.net/npm/instantsearch.js@2.10.4"></script><!--link(rel="dns-prefetch" href="https://cdn.jsdelivr.net")--><!--link(rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.1.1/dist/instantsearch.min.css")--><!--script(src="https://cdn.jsdelivr.net/npm/instantsearch.js@2.1.1/dist/instantsearch.min.js" defer)--><script>var isPassword = '' || false;
if (isPassword) {
    if (prompt('请输入文章密码') !== '') {
        alert('密码错误！');
        history.back();
    }
}</script><script>window.GLOBAL_CONFIG = {
  root: '/',
  algolia: {"appId":"X7RY6NGU4G","apiKey":"bf7ed65264918bbc03f12b4cc1212d85","indexName":"myblog","hits":{"per_page":10},"languages":{"input_placeholder":"搜索文章","hits_empty":"找不到您查询的内容:${query}","hits_stats":"找到 ${hits} 条结果，用时 ${time} 毫秒"}},
  localSearch: undefined,
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  }
}</script></head><body><canvas id="universe"></canvas><!--#body--><div id="sidebar"><div class="author-info"><div class="author-info-avatar"><img class="author-info-avatar-img" src="/avatar.png"></div><div class="author-info-name">bb</div><div class="author-info-description">This is myblog!</div><div class="links-buttons"><a class="links-button button-hover" href="https://github.com/bbkali" target="_blank">GitHub<i class="icon-dot bg-color6"></i></a><a class="links-button button-hover" href="mailto:shuiyue75381@gmail.com" target="_blank">E-Mail<i class="icon-dot bg-color3"></i></a><a class="links-button button-hover" href="tencent://message/?uin=1019593584&amp;Site=&amp;Menu=yes" target="_blank">QQ<i class="icon-dot bg-color2"></i></a></div><div class="author-info-articles"><a class="author-info-articles-archives article-meta" href="/archives"><span class="pull-top">日志</span><span class="pull-bottom">86</span></a><a class="author-info-articles-tags article-meta" href="/tags"><span class="pull-top">标签</span><span class="pull-bottom">66</span></a><a class="author-info-articles-categories article-meta" href="/categories"><span class="pull-top">分类</span><span class="pull-bottom">33</span></a></div></div></div><div id="main-container"><header><div id="menu-outer"><i class="menu-list-icon fas fa-bars"></i><nav id="menu-inner"><a class="menu-item" href="/">首页</a><a class="menu-item" href="/tags">标签</a><a class="menu-item" href="/categories">分类</a><a class="menu-item" href="/archives">归档</a><a class="menu-item" href="/about">关于</a></nav><div class="right-info"><a class="search social-icon"><i class="fas fa-search"></i><span> 搜索</span></a><a class="title-name" href="/">bb的博客</a><span id="now-time"></span></div></div></header><div id="content-outer"><div id="content-inner"><div id="recent-posts"><!-- each post in page.posts.sort('date', -1).limit(10).toArray()--><!-- config中配置按照什么排序--><div class="recent-post-item"><a class="post-title" href="/2020/01/19/scrapy-入门篇/">scrapy-入门篇</a><div class="container"><time class="button-hover post-date"><i class="fas fa-calendar-alt article-icon" aria-hidden="true"></i> 更新于 2020-02-06</time><div class="button-hover categories"><i class="fa fa-inbox article-icon" aria-hidden="true"></i><a class="link-a" href="/categories/Scrapy/">Scrapy</a></div><div class="button-hover tags"><i class="fa fa-tag article-icon" aria-hidden="true"></i><a class="link-a" href="/tags/Scrapy/">Scrapy</a></div></div><div class="post-content"><div class="main-content content"><h1 id="Scrapy教程01-入门篇"><a href="#Scrapy教程01-入门篇" class="headerlink" title="Scrapy教程01- 入门篇"></a>Scrapy教程01- 入门篇</h1><p>Scrapy是一个为了爬取网站数据，提取结构性数据而编写的应用框架。可以应用在包括数据挖掘，<br>信息处理或存储历史数据等一系列的程序中。其最初是为了页面抓取(更确切来说,网络抓取)所设计的，<br>也可以应用在获取API所返回的数据(比如Web Services)或者通用的网络爬虫。</p>
<p>Scrapy也能帮你实现高阶的爬虫框架，比如爬取时的网站认证、内容的分析处理、重复抓取、分布式爬取等等很复杂的事。</p>
<h2 id="安装scrapy"><a href="#安装scrapy" class="headerlink" title="安装scrapy"></a>安装scrapy</h2><p>我的测试环境是centos6.5</p>
<p>升级python到最新版的2.7，下面的所有步骤都切换到root用户</p>
<p>由于scrapy目前只能运行在python2上，所以先更新centos上面的python到最新的<br><a href="https://www.python.org/downloads/release/python-2711/" target="_blank" rel="noopener">Python 2.7.11</a>，<br>具体方法请google下很多这样的教程。</p>
<p>先安装一些依赖软件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">yum install python-devel</span><br><span class="line">yum install libffi-devel</span><br><span class="line">yum install openssl-devel</span><br></pre></td></tr></table></figure></p>
<p>然后安装pyopenssl库<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install pyopenssl</span><br></pre></td></tr></table></figure></p>
<p>安装xlml<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">yum install python-lxml</span><br><span class="line">yum install libxml2-devel</span><br><span class="line">yum install libxslt-devel</span><br></pre></td></tr></table></figure></p>
<p>安装service-identity<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install service-identity</span><br></pre></td></tr></table></figure></p>
<p>安装twisted<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install scrapy</span><br></pre></td></tr></table></figure></p>
<p>安装scrapy<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install scrapy -U</span><br></pre></td></tr></table></figure></p>
<p>测试scrapy<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy bench</span><br></pre></td></tr></table></figure></p>
<p>最终成功，太不容易了！</p>
<h2 id="简单示例"><a href="#简单示例" class="headerlink" title="简单示例"></a>简单示例</h2><p>创建一个python源文件，名为stackoverflow.py，内容如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">StackOverflowSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'stackoverflow'</span></span><br><span class="line">    start_urls = [<span class="string">'http://stackoverflow.com/questions?sort=votes'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> href <span class="keyword">in</span> response.css(<span class="string">'.question-summary h3 a::attr(href)'</span>):</span><br><span class="line">            full_url = response.urljoin(href.extract())</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(full_url, callback=self.parse_question)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_question</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="keyword">yield</span> &#123;</span><br><span class="line">            <span class="string">'title'</span>: response.css(<span class="string">'h1 a::text'</span>).extract()[<span class="number">0</span>],</span><br><span class="line">            <span class="string">'votes'</span>: response.css(<span class="string">'.question .vote-count-post::text'</span>).extract()[<span class="number">0</span>],</span><br><span class="line">            <span class="string">'body'</span>: response.css(<span class="string">'.question .post-text'</span>).extract()[<span class="number">0</span>],</span><br><span class="line">            <span class="string">'tags'</span>: response.css(<span class="string">'.question .post-tag::text'</span>).extract(),</span><br><span class="line">            <span class="string">'link'</span>: response.url,</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure>
<p>运行：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy runspider stackoverflow_spider.py -o top-stackoverflow-questions.json</span><br></pre></td></tr></table></figure></p>
<p>结果类似下面：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[&#123;</span><br><span class="line">    &quot;body&quot;: &quot;... LONG HTML HERE ...&quot;,</span><br><span class="line">    &quot;link&quot;: &quot;http://stackoverflow.com/questions/11227809/why-is-processing-a-sorted-array-faster-than-an-unsorted-array&quot;,</span><br><span class="line">    &quot;tags&quot;: [&quot;java&quot;, &quot;c++&quot;, &quot;performance&quot;, &quot;optimization&quot;],</span><br><span class="line">    &quot;title&quot;: &quot;Why is processing a sorted array faster than an unsorted array?&quot;,</span><br><span class="line">    &quot;votes&quot;: &quot;9924&quot;</span><br><span class="line">&#125;,</span><br><span class="line">&#123;</span><br><span class="line">    &quot;body&quot;: &quot;... LONG HTML HERE ...&quot;,</span><br><span class="line">    &quot;link&quot;: &quot;http://stackoverflow.com/questions/1260748/how-do-i-remove-a-git-submodule&quot;,</span><br><span class="line">    &quot;tags&quot;: [&quot;git&quot;, &quot;git-submodules&quot;],</span><br><span class="line">    &quot;title&quot;: &quot;How do I remove a Git submodule?&quot;,</span><br><span class="line">    &quot;votes&quot;: &quot;1764&quot;</span><br><span class="line">&#125;,</span><br><span class="line">...]</span><br></pre></td></tr></table></figure></p>
<p>当你运行<code>scrapy runspider somefile.py</code>这条语句的时候，Scrapy会去寻找源文件中定义的一个spider并且交给爬虫引擎来执行它。<br><code>start_urls</code>属性定义了开始的URL，爬虫会通过它来构建初始的请求，返回response后再调用默认的回调方法<code>parse</code>并传入这个response。<br>我们在<code>parse</code>回调方法中通过使用css选择器提取每个提问页面链接的href属性值，然后<code>yield</code>另外一个请求，<br>并注册<code>parse_question</code>回调方法，在这个请求完成后被执行。</p>
<p>处理流程图：</p>
<p><img src="https://raw.githubusercontent.com/bbkali/picbad/master/2020-1-19-17-30-31" alt="2020-1-19-17-30-31"></p>
<p>Scrapy的一个好处是所有请求都是被调度并异步处理，就算某个请求出错也不影响其他请求继续被处理。</p>
<p>我们的示例中将解析结果生成json格式，你还可以导出为其他格式（比如XML、CSV），或者是将其存储到FTP、Amazon S3上。<br>你还可以通过<a href="http://doc.scrapy.org/en/1.0/topics/item-pipeline.html#topics-item-pipeline" target="_blank" rel="noopener">pipeline</a><br>将它们存储到数据库中去，这些数据保存的方式各种各样。</p>
<h2 id="Scrapy特性一览"><a href="#Scrapy特性一览" class="headerlink" title="Scrapy特性一览"></a>Scrapy特性一览</h2><p>你已经可以通过Scrapy从一个网站上面爬取数据并将其解析保存下来了，但是这只是Scrapy的皮毛。<br>Scrapy提供了更多的特性来让你爬取更加容易和高效。比如：</p>
<ol>
<li>内置支持扩展的CSS选择器和XPath表达式来从HTML/XML源码中选择并提取数据，还能使用正则表达式</li>
<li>提供交互式shell控制台试验CSS和XPath表达式，这个在调试你的蜘蛛程序时很有用</li>
<li>内置支持生成多种格式的订阅导出（JSON、CSV、XML）并将它们存储在多个位置（FTP、S3、本地文件系统）</li>
<li>健壮的编码支持和自动识别，用于处理外文、非标准和错误编码问题</li>
<li>可扩展，允许你使用<a href="http://doc.scrapy.org/en/1.0/topics/signals.html#topics-signals" target="_blank" rel="noopener">signals</a><br>和友好的API(middlewares, extensions, 和pipelines)来编写自定义插件功能。</li>
<li>大量的内置扩展和中间件供使用：<ul>
<li>cookies and session handling</li>
<li>HTTP features like compression, authentication, caching</li>
<li>user-agent spoofing</li>
<li>robots.txt</li>
<li>crawl depth restriction</li>
<li>and more</li>
</ul>
</li>
<li>还有其他好多好东东，比如可重复利用蜘蛛来爬取<a href="http://www.sitemaps.org/" target="_blank" rel="noopener">Sitemaps</a>和XML/CSV订阅，<br>一个跟爬取元素关联的媒体管道来<br><a href="http://doc.scrapy.org/en/1.0/topics/media-pipeline.html#topics-media-pipeline" target="_blank" rel="noopener">自动下载图片</a>，<br>一个缓存DNS解析器等等。</li>
</ol>
</div></div><a class="button-hover more" href="/2020/01/19/scrapy-入门篇/#more">阅读全文</a></div><div class="recent-post-item"><a class="post-title" href="/2020/01/19/scrapy-内置服务/">scrapy-内置服务</a><div class="container"><time class="button-hover post-date"><i class="fas fa-calendar-alt article-icon" aria-hidden="true"></i> 更新于 2020-02-06</time><div class="button-hover categories"><i class="fa fa-inbox article-icon" aria-hidden="true"></i><a class="link-a" href="/categories/Scrapy/">Scrapy</a></div><div class="button-hover tags"><i class="fa fa-tag article-icon" aria-hidden="true"></i><a class="link-a" href="/tags/Scrapy/">Scrapy</a></div></div><div class="post-content"><div class="main-content content"><h1 id="Scrapy教程07-内置服务"><a href="#Scrapy教程07-内置服务" class="headerlink" title="Scrapy教程07- 内置服务"></a>Scrapy教程07- 内置服务</h1><p>Scrapy使用Python内置的的日志系统来记录事件日志。<br>日志配置<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">LOG_ENABLED = true</span><br><span class="line">LOG_ENCODING = <span class="string">"utf-8"</span></span><br><span class="line">LOG_LEVEL = logging.INFO</span><br><span class="line">LOG_FILE = <span class="string">"log/spider.log"</span></span><br><span class="line">LOG_STDOUT = <span class="literal">True</span></span><br><span class="line">LOG_FORMAT = <span class="string">"%(asctime)s [%(name)s] %(levelname)s: %(message)s"</span></span><br><span class="line">LOG_DATEFORMAT = <span class="string">"%Y-%m-%d %H:%M:%S"</span></span><br></pre></td></tr></table></figure></p>
<p>使用也很简单<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> logging</span><br><span class="line">logger = logging.getLogger(__name__)</span><br><span class="line">logger.warning(<span class="string">"This is a warning"</span>)</span><br></pre></td></tr></table></figure></p></div></div><a class="button-hover more" href="/2020/01/19/scrapy-内置服务/#more">阅读全文</a></div><div class="recent-post-item"><a class="post-title" href="/2020/01/19/scrapy-模拟登录/">scrapy-模拟登录</a><div class="container"><time class="button-hover post-date"><i class="fas fa-calendar-alt article-icon" aria-hidden="true"></i> 更新于 2020-02-06</time><div class="button-hover categories"><i class="fa fa-inbox article-icon" aria-hidden="true"></i><a class="link-a" href="/categories/Scrapy/">Scrapy</a></div><div class="button-hover tags"><i class="fa fa-tag article-icon" aria-hidden="true"></i><a class="link-a" href="/tags/Scrapy/">Scrapy</a></div></div><div class="post-content"><div class="main-content content"><h1 id="Scrapy教程11-模拟登录"><a href="#Scrapy教程11-模拟登录" class="headerlink" title="Scrapy教程11- 模拟登录"></a>Scrapy教程11- 模拟登录</h1><p>有时候爬取网站的时候需要登录，在Scrapy中可以通过模拟登录保存cookie后再去爬取相应的页面。这里我通过登录github然后爬取自己的issue列表来演示下整个原理。</p>
<p>要想实现登录就需要表单提交，先通过浏览器访问github的登录页面<a href="https://github.com/login" target="_blank" rel="noopener">https://github.com/login</a>，<br>然后使用浏览器调试工具来得到登录时需要提交什么东西:</p>
<p><img src="https://raw.githubusercontent.com/bbkali/picbad/master/2020-1-19-17-31-18" alt="2020-1-19-17-31-18"></p>
<p>我这里使用chrome浏览器的调试工具，F12打开后选择Network，并将Preserve log勾上。<br>我故意输入错误的用户名和密码，得到它提交的form表单参数还有POST提交的URL:<br></p></div></div><a class="button-hover more" href="/2020/01/19/scrapy-模拟登录/#more">阅读全文</a></div><div class="recent-post-item"><a class="post-title" href="/2020/01/19/scrapy-动态配置爬虫/">scrapy-动态配置爬虫</a><div class="container"><time class="button-hover post-date"><i class="fas fa-calendar-alt article-icon" aria-hidden="true"></i> 更新于 2020-02-06</time><div class="button-hover categories"><i class="fa fa-inbox article-icon" aria-hidden="true"></i><a class="link-a" href="/categories/Scrapy/">Scrapy</a></div><div class="button-hover tags"><i class="fa fa-tag article-icon" aria-hidden="true"></i><a class="link-a" href="/tags/Scrapy/">Scrapy</a></div></div><div class="post-content"><div class="main-content content"><h1 id="Scrapy教程10-动态配置爬虫"><a href="#Scrapy教程10-动态配置爬虫" class="headerlink" title="Scrapy教程10- 动态配置爬虫"></a>Scrapy教程10- 动态配置爬虫</h1><p>有很多时候我们需要从多个网站爬取所需要的数据，比如我们想爬取多个网站的新闻，将其存储到数据库同一个表中。我们是不是要对每个网站都得去定义一个Spider类呢？<br>其实不需要，我们可以通过维护一个规则配置表或者一个规则配置文件来动态增加或修改爬取规则，然后程序代码不需要更改就能实现多个网站爬取。</p>
<p>要这样做，我们就不能再使用前面的<code>scrapy crawl test</code>这种命令了，我们需要使用编程的方式运行Scrapy spider，参考<a href="http://doc.scrapy.org/en/1.0/topics/practices.html#run-scrapy-from-a-script" target="_blank" rel="noopener">官方文档</a></p>
<h3 id="脚本运行Scrapy"><a href="#脚本运行Scrapy" class="headerlink" title="脚本运行Scrapy"></a>脚本运行Scrapy</h3><p>可以利用scrapy提供的<a href="http://doc.scrapy.org/en/1.0/topics/api.html#topics-api" target="_blank" rel="noopener">核心API</a>通过编程方式启动scrapy，代替传统的<code>scrapy crawl</code>启动方式。</p>
<p>Scrapy构建于Twisted异步网络框架基础之上，因此你需要在Twisted reactor里面运行。</p>
<p>首先你可以使用<code>scrapy.crawler.CrawlerProcess</code>这个类来运行你的spider，这个类会为你启动一个Twisted reactor，并能配置你的日志和shutdown处理器。所有的scrapy命令都使用这个类。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> scrapy.crawler <span class="keyword">import</span> CrawlerProcess</span><br><span class="line"><span class="keyword">from</span> scrapy.utils.project <span class="keyword">import</span> get_project_settings</span><br><span class="line"></span><br><span class="line">process = CrawlerProcess(get_project_settings())</span><br><span class="line"></span><br><span class="line">process.crawl(MySpider)</span><br><span class="line">process.start() <span class="comment"># the script will block here until the crawling is finished</span></span><br></pre></td></tr></table></figure></p>
<p>然后你就可以直接执行这个脚本<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python run.py</span><br></pre></td></tr></table></figure></p></div></div><a class="button-hover more" href="/2020/01/19/scrapy-动态配置爬虫/#more">阅读全文</a></div><div class="recent-post-item"><a class="post-title" href="/2020/01/19/scrapy-部署/">scrapy-部署</a><div class="container"><time class="button-hover post-date"><i class="fas fa-calendar-alt article-icon" aria-hidden="true"></i> 更新于 2020-02-06</time><div class="button-hover categories"><i class="fa fa-inbox article-icon" aria-hidden="true"></i><a class="link-a" href="/categories/Scrapy/">Scrapy</a></div><div class="button-hover tags"><i class="fa fa-tag article-icon" aria-hidden="true"></i><a class="link-a" href="/tags/Scrapy/">Scrapy</a></div></div><div class="post-content"><div class="main-content content"><h1 id="Scrapy教程09-部署"><a href="#Scrapy教程09-部署" class="headerlink" title="Scrapy教程09- 部署"></a>Scrapy教程09- 部署</h1><p>本篇主要介绍两种部署爬虫的方案。如果仅仅在开发调试的时候在本地部署跑起来是很容易的，不过要是生产环境，爬虫任务量大，并且持续时间长，那么还是建议使用专业的部署方法。主要是两种方案：</p>
<ul>
<li><a href="http://doc.scrapy.org/en/1.0/topics/deploy.html#deploy-scrapyd" target="_blank" rel="noopener">Scrapyd</a> 开源方案</li>
<li><a href="http://doc.scrapy.org/en/1.0/topics/deploy.html#deploy-scrapy-cloud" target="_blank" rel="noopener">Scrapy Cloud</a> 云方案</li>
</ul>
<h2 id="部署到Scrapyd"><a href="#部署到Scrapyd" class="headerlink" title="部署到Scrapyd"></a>部署到Scrapyd</h2><p><a href="http://doc.scrapy.org/en/1.0/topics/deploy.html#deploy-scrapyd" target="_blank" rel="noopener">Scrapyd</a>是一个开源软件，用来运行蜘蛛爬虫。它提供了HTTP API的服务器，还能运行和监控Scrapy的蜘蛛</p>
<p>要部署爬虫到Scrapyd，需要使用到<a href="https://github.com/scrapy/scrapyd-client" target="_blank" rel="noopener">scrapyd-client</a>部署工具集，下面我演示下部署的步骤</p>
<p>Scrapyd通常以守护进程daemon形式运行，监听spider的请求，然后为每个spider创建一个进程执行<code>scrapy crawl myspider</code>,同时Scrapyd还能以多进程方式启动，通过配置<code>max_proc</code>和<code>max_proc_per_cpu</code>选项</p>
<h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>使用pip安装<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install scrapyd</span><br></pre></td></tr></table></figure></p>
<p>在ubuntu系统上面<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">apt-get install scrapyd</span><br></pre></td></tr></table></figure></p></div></div><a class="button-hover more" href="/2020/01/19/scrapy-部署/#more">阅读全文</a></div></div><div id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/page/3/"><i class="fas fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span><a class="page-number" href="/page/5/">5</a><span class="space">&hellip;</span><a class="page-number" href="/page/18/">18</a><a class="extend next" rel="next" href="/page/5/"><i class="fas fa-angle-right"></i></a></div></div></div></div><div class="button-hover" id="return-top"><i class="fas fa-arrow-up" aria-hidden="true"></i></div><footer><div id="footer"><div class="button-hover" id="side-button"><i class="fas fa-arrow-right"></i></div><div class="right-content"><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_site_uv"><i class="fas fa-user"></i></span><span id="busuanzi_value_site_uv"></span><span></span><span class="footer-separator">|</span><span id="busuanzi_container_site_pv"><i class="fas fa-eye"></i></span><span id="busuanzi_value_site_pv"></span><span></span></div><div class="copyright">&copy;2019 ～ 2020 By bb</div></div></div></footer></div><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/thirdparty/jquery-3.3.1.min.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/thirdparty/velocity.min.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/thirdparty/jquery.mCustomScrollbar.concat.min.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/fan.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/canvas_bg.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/utils.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/scroll.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/sidebar.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/copy.js"></script><!--script(src=url)--><div class="search-dialog"><div id="algolia-search-title">Algolia</div><div class="search-close-button"><i class="fa fa-times"></i></div><!--div#current-refined-values--><!--div#clear-all--><div id="search-box"></div><!--div#refinement-list--><hr><div id="hits"></div><div id="algolia-pagination"></div></div><div class="search-mask"></div><script src="/js/search/algolia.js"></script></body></html>