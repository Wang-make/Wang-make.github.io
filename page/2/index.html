<!DOCTYPE html><html><head><meta name="generator" content="Hexo 3.9.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="This is myblog!"><meta name="keywords" content><meta name="author" content="bb,shuiyue75381@gmail.com"><meta name="copyright" content="bb"><title>【bb的博客】</title><link rel="stylesheet" href="/css/fan.css"><link rel="stylesheet" href="/css/thirdparty/jquery.mCustomScrollbar.min.css"><link rel="icon" href="/favicon.ico"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.10.4/dist/instantsearch.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.10.4/dist/instantsearch-theme-algolia.min.css"><script src="https://cdn.jsdelivr.net/npm/instantsearch.js@2.10.4"></script><!--link(rel="dns-prefetch" href="https://cdn.jsdelivr.net")--><!--link(rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.1.1/dist/instantsearch.min.css")--><!--script(src="https://cdn.jsdelivr.net/npm/instantsearch.js@2.1.1/dist/instantsearch.min.js" defer)--><script>var isPassword = '' || false;
if (isPassword) {
    if (prompt('请输入文章密码') !== '') {
        alert('密码错误！');
        history.back();
    }
}</script><script>window.GLOBAL_CONFIG = {
  root: '/',
  algolia: {"appId":"X7RY6NGU4G","apiKey":"bf7ed65264918bbc03f12b4cc1212d85","indexName":"myblog","hits":{"per_page":10},"languages":{"input_placeholder":"搜索文章","hits_empty":"找不到您查询的内容:${query}","hits_stats":"找到 ${hits} 条结果，用时 ${time} 毫秒"}},
  localSearch: undefined,
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  }
}</script></head><body><canvas id="universe"></canvas><!--#body--><div id="sidebar"><div class="author-info"><div class="author-info-avatar"><img class="author-info-avatar-img" src="/avatar.png"></div><div class="author-info-name">bb</div><div class="author-info-description">This is myblog!</div><div class="links-buttons"><a class="links-button button-hover" href="https://github.com/bbkali" target="_blank">GitHub<i class="icon-dot bg-color8"></i></a><a class="links-button button-hover" href="mailto:shuiyue75381@gmail.com" target="_blank">E-Mail<i class="icon-dot bg-color5"></i></a><a class="links-button button-hover" href="tencent://message/?uin=1019593584&amp;Site=&amp;Menu=yes" target="_blank">QQ<i class="icon-dot bg-color7"></i></a></div><div class="author-info-articles"><a class="author-info-articles-archives article-meta" href="/archives"><span class="pull-top">日志</span><span class="pull-bottom">80</span></a><a class="author-info-articles-tags article-meta" href="/tags"><span class="pull-top">标签</span><span class="pull-bottom">65</span></a><a class="author-info-articles-categories article-meta" href="/categories"><span class="pull-top">分类</span><span class="pull-bottom">31</span></a></div></div></div><div id="main-container"><header><div id="menu-outer"><i class="menu-list-icon fas fa-bars"></i><nav id="menu-inner"><a class="menu-item" href="/">首页</a><a class="menu-item" href="/tags">标签</a><a class="menu-item" href="/categories">分类</a><a class="menu-item" href="/archives">归档</a><a class="menu-item" href="/about">关于</a></nav><div class="right-info"><a class="search social-icon"><i class="fas fa-search"></i><span> 搜索</span></a><a class="title-name" href="/">bb的博客</a><span id="now-time"></span></div></div></header><div id="content-outer"><div id="content-inner"><div id="recent-posts"><!-- each post in page.posts.sort('date', -1).limit(10).toArray()--><!-- config中配置按照什么排序--><div class="recent-post-item"><a class="post-title" href="/2020/01/19/scrapy-Item Pipeline/">scrapy-Item Pipeline</a><div class="container"><time class="button-hover post-date"><i class="fas fa-calendar-alt article-icon" aria-hidden="true"></i> 更新于 2020-01-22</time><div class="button-hover categories"><i class="fa fa-inbox article-icon" aria-hidden="true"></i><a class="link-a" href="/categories/Scrapy/">Scrapy</a></div><div class="button-hover tags"><i class="fa fa-tag article-icon" aria-hidden="true"></i><a class="link-a" href="/tags/Scrapy/">Scrapy</a></div></div><div class="post-content"><div class="main-content content"><h1 id="Scrapy教程06-Item-Pipeline"><a href="#Scrapy教程06-Item-Pipeline" class="headerlink" title="Scrapy教程06- Item Pipeline"></a>Scrapy教程06- Item Pipeline</h1><p>当一个item被蜘蛛爬取到之后会被发送给Item Pipeline，然后多个组件按照顺序处理这个item。<br>每个Item Pipeline组件其实就是一个实现了一个简单方法的Python类。他们接受一个item并在上面执行逻辑，还能决定这个item到底是否还要继续往下传输，如果不要了就直接丢弃。</p>
<p>使用Item Pipeline的常用场景：</p>
<ul>
<li>清理HTML数据</li>
<li>验证被抓取的数据(检查item是否包含某些字段)</li>
<li>重复性检查(然后丢弃)</li>
<li>将抓取的数据存储到数据库中</li></ul></div></div><a class="button-hover more" href="/2020/01/19/scrapy-Item Pipeline/#more">阅读全文</a></div><div class="recent-post-item"><a class="post-title" href="/2020/01/19/scrapy-抓取动态网站/">scrapy-抓取动态网站</a><div class="container"><time class="button-hover post-date"><i class="fas fa-calendar-alt article-icon" aria-hidden="true"></i> 更新于 2020-01-22</time><div class="button-hover categories"><i class="fa fa-inbox article-icon" aria-hidden="true"></i><a class="link-a" href="/categories/Scrapy/">Scrapy</a></div><div class="button-hover tags"><i class="fa fa-tag article-icon" aria-hidden="true"></i><a class="link-a" href="/tags/Scrapy/">Scrapy</a></div></div><div class="post-content"><div class="main-content content"><h1 id="Scrapy教程12-抓取动态网站"><a href="#Scrapy教程12-抓取动态网站" class="headerlink" title="Scrapy教程12- 抓取动态网站"></a>Scrapy教程12- 抓取动态网站</h1><p>前面我们介绍的都是去抓取静态的网站页面，也就是说我们打开某个链接，它的内容全部呈现出来。<br>但是如今的互联网大部分的web页面都是动态的，经常逛的网站例如京东、淘宝等，商品列表都是js，并有Ajax渲染，<br>下载某个链接得到的页面里面含有异步加载的内容，这样再使用之前的方式我们根本获取不到异步加载的这些网页内容。</p>
<p>使用Javascript渲染和处理网页是种非常常见的做法，如何处理一个大量使用Javascript的页面是Scrapy爬虫开发中一个常见的问题，<br>这篇文章将说明如何在Scrapy爬虫中使用<a href="https://github.com/scrapy-plugins/scrapy-splash" target="_blank" rel="noopener">scrapy-splash</a>来处理页面中得Javascript。</p>
<h3 id="scrapy-splash简介"><a href="#scrapy-splash简介" class="headerlink" title="scrapy-splash简介"></a>scrapy-splash简介</h3><p>scrapy-splash利用<a href="https://github.com/scrapy/scrapy" target="_blank" rel="noopener">Splash</a>将javascript和Scrapy集成起来，使得Scrapy可以抓取动态网页。</p>
<p>Splash是一个javascript渲染服务，是实现了HTTP API的轻量级浏览器，底层基于Twisted和QT框架，Python语言编写。所以首先你得安装Splash实例<br></p></div></div><a class="button-hover more" href="/2020/01/19/scrapy-抓取动态网站/#more">阅读全文</a></div><div class="recent-post-item"><a class="post-title" href="/2020/01/19/scrapy-文件与图片/">scrapy-文件与图片</a><div class="container"><time class="button-hover post-date"><i class="fas fa-calendar-alt article-icon" aria-hidden="true"></i> 更新于 2020-01-22</time><div class="button-hover categories"><i class="fa fa-inbox article-icon" aria-hidden="true"></i><a class="link-a" href="/categories/Scrapy/">Scrapy</a></div><div class="button-hover tags"><i class="fa fa-tag article-icon" aria-hidden="true"></i><a class="link-a" href="/tags/Scrapy/">Scrapy</a></div></div><div class="post-content"><div class="main-content content"><h1 id="Scrapy教程08-文件与图片"><a href="#Scrapy教程08-文件与图片" class="headerlink" title="Scrapy教程08- 文件与图片"></a>Scrapy教程08- 文件与图片</h1><p>Scrapy为我们提供了可重用的<a href="http://doc.scrapy.org/en/1.0/topics/item-pipeline.html" target="_blank" rel="noopener">item pipelines</a>为某个特定的Item去下载文件。<br>通常来说你会选择使用Files Pipeline或Images Pipeline。</p>
<p>这两个管道都实现了：</p>
<ul>
<li>避免重复下载</li>
<li>可以指定下载后保存的地方(文件系统目录中,Amazon S3中)</li>
</ul>
<p>Images Pipeline为处理图片提供了额外的功能：</p>
<ul>
<li>将所有下载的图片格式转换成普通的JPG并使用RGB颜色模式</li>
<li>生成缩略图</li>
<li>检查图片的宽度和高度确保它们满足最小的尺寸限制</li>
</ul>
<p>管道同时会在内部保存一个被调度下载的URL列表，然后将包含相同媒体的相应关联到这个队列上来，从而防止了多个item共享这个媒体时重复下载。<br></p></div></div><a class="button-hover more" href="/2020/01/19/scrapy-文件与图片/#more">阅读全文</a></div><div class="recent-post-item"><a class="post-title" href="/2020/01/19/scrapy-完整示例/">scrapy-完整示例</a><div class="container"><time class="button-hover post-date"><i class="fas fa-calendar-alt article-icon" aria-hidden="true"></i> 更新于 2020-01-22</time><div class="button-hover categories"><i class="fa fa-inbox article-icon" aria-hidden="true"></i><a class="link-a" href="/categories/Scrapy/">Scrapy</a></div><div class="button-hover tags"><i class="fa fa-tag article-icon" aria-hidden="true"></i><a class="link-a" href="/tags/Scrapy/">Scrapy</a></div></div><div class="post-content"><div class="main-content content"><h1 id="Scrapy教程02-完整示例"><a href="#Scrapy教程02-完整示例" class="headerlink" title="Scrapy教程02- 完整示例"></a>Scrapy教程02- 完整示例</h1><p>这篇文章我们通过一个比较完整的例子来教你使用Scrapy，我选择爬取<a href="http://www.huxiu.com/" target="_blank" rel="noopener">虎嗅网首页</a>的新闻列表。</p>
<p>这里我们将完成如下几个步骤：</p>
<ul>
<li>创建一个新的Scrapy工程</li>
<li>定义你所需要要抽取的Item对象</li>
<li>编写一个spider来爬取某个网站并提取出所有的Item对象</li>
<li>编写一个Item Pipline来存储提取出来的Item对象</li>
</ul>
<p>Scrapy使用Python语言编写，如果你对这门语言还不熟，请先去学习下基本知识。</p>
<h2 id="创建Scrapy工程"><a href="#创建Scrapy工程" class="headerlink" title="创建Scrapy工程"></a>创建Scrapy工程</h2><p>在任何你喜欢的目录执行如下命令<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy startproject coolscrapy</span><br></pre></td></tr></table></figure></p>
<p>将会创建coolscrapy文件夹，其目录结构如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">coolscrapy/</span><br><span class="line">    scrapy.cfg            # 部署配置文件</span><br><span class="line"></span><br><span class="line">    coolscrapy/           # Python模块，你所有的代码都放这里面</span><br><span class="line">        __init__.py</span><br><span class="line"></span><br><span class="line">        items.py          # Item定义文件</span><br><span class="line"></span><br><span class="line">        pipelines.py      # pipelines定义文件</span><br><span class="line"></span><br><span class="line">        settings.py       # 配置文件</span><br><span class="line"></span><br><span class="line">        spiders/          # 所有爬虫spider都放这个文件夹下面</span><br><span class="line">            __init__.py</span><br><span class="line">            ...</span><br></pre></td></tr></table></figure></p>
<h2 id="定义我们的Item"><a href="#定义我们的Item" class="headerlink" title="定义我们的Item"></a>定义我们的Item</h2><p>我们通过创建一个scrapy.Item类，并定义它的类型为scrapy.Field的属性，<br>我们准备将虎嗅网新闻列表的名称、链接地址和摘要爬取下来。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HuxiuItem</span><span class="params">(scrapy.Item)</span>:</span></span><br><span class="line">    title = scrapy.Field()    <span class="comment"># 标题</span></span><br><span class="line">    link = scrapy.Field()     <span class="comment"># 链接</span></span><br><span class="line">    desc = scrapy.Field()     <span class="comment"># 简述</span></span><br><span class="line">    posttime = scrapy.Field() <span class="comment"># 发布时间</span></span><br></pre></td></tr></table></figure>
<p>也许你觉得定义这个Item有点麻烦，但是定义完之后你可以得到许多好处，这样你就可以使用Scrapy中其他有用的组件和帮助类。</p>
<h2 id="第一个Spider"><a href="#第一个Spider" class="headerlink" title="第一个Spider"></a>第一个Spider</h2><p>蜘蛛就是你定义的一些类，Scrapy使用它们来从一个domain（或domain组）爬取信息。<br>在蜘蛛类中定义了一个初始化的URL下载列表，以及怎样跟踪链接，如何解析页面内容来提取Item。</p>
<p>定义一个Spider，只需继承<code>scrapy.Spider</code>类并定于一些属性：</p>
<ul>
<li>name: Spider名称，必须是唯一的</li>
<li>start_urls: 初始化下载链接URL</li>
<li>parse(): 用来解析下载后的Response对象，该对象也是这个方法的唯一参数。<br>它负责解析返回页面数据并提取出相应的Item（返回Item对象），还有其他合法的链接URL（返回Request对象）。</li></ul></div></div><a class="button-hover more" href="/2020/01/19/scrapy-完整示例/#more">阅读全文</a></div><div class="recent-post-item"><a class="post-title" href="/2020/01/19/scrapy-入门篇/">scrapy-入门篇</a><div class="container"><time class="button-hover post-date"><i class="fas fa-calendar-alt article-icon" aria-hidden="true"></i> 更新于 2020-01-22</time><div class="button-hover categories"><i class="fa fa-inbox article-icon" aria-hidden="true"></i><a class="link-a" href="/categories/Scrapy/">Scrapy</a></div><div class="button-hover tags"><i class="fa fa-tag article-icon" aria-hidden="true"></i><a class="link-a" href="/tags/Scrapy/">Scrapy</a></div></div><div class="post-content"><div class="main-content content"><h1 id="Scrapy教程01-入门篇"><a href="#Scrapy教程01-入门篇" class="headerlink" title="Scrapy教程01- 入门篇"></a>Scrapy教程01- 入门篇</h1><p>Scrapy是一个为了爬取网站数据，提取结构性数据而编写的应用框架。可以应用在包括数据挖掘，<br>信息处理或存储历史数据等一系列的程序中。其最初是为了页面抓取(更确切来说,网络抓取)所设计的，<br>也可以应用在获取API所返回的数据(比如Web Services)或者通用的网络爬虫。</p>
<p>Scrapy也能帮你实现高阶的爬虫框架，比如爬取时的网站认证、内容的分析处理、重复抓取、分布式爬取等等很复杂的事。</p>
<h2 id="安装scrapy"><a href="#安装scrapy" class="headerlink" title="安装scrapy"></a>安装scrapy</h2><p>我的测试环境是centos6.5</p>
<p>升级python到最新版的2.7，下面的所有步骤都切换到root用户</p>
<p>由于scrapy目前只能运行在python2上，所以先更新centos上面的python到最新的<br><a href="https://www.python.org/downloads/release/python-2711/" target="_blank" rel="noopener">Python 2.7.11</a>，<br>具体方法请google下很多这样的教程。</p>
<p>先安装一些依赖软件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">yum install python-devel</span><br><span class="line">yum install libffi-devel</span><br><span class="line">yum install openssl-devel</span><br></pre></td></tr></table></figure></p>
<p>然后安装pyopenssl库<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install pyopenssl</span><br></pre></td></tr></table></figure></p>
<p>安装xlml<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">yum install python-lxml</span><br><span class="line">yum install libxml2-devel</span><br><span class="line">yum install libxslt-devel</span><br></pre></td></tr></table></figure></p>
<p>安装service-identity<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install service-identity</span><br></pre></td></tr></table></figure></p>
<p>安装twisted<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install scrapy</span><br></pre></td></tr></table></figure></p>
<p>安装scrapy<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install scrapy -U</span><br></pre></td></tr></table></figure></p>
<p>测试scrapy<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy bench</span><br></pre></td></tr></table></figure></p>
<p>最终成功，太不容易了！</p>
<h2 id="简单示例"><a href="#简单示例" class="headerlink" title="简单示例"></a>简单示例</h2><p>创建一个python源文件，名为stackoverflow.py，内容如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">StackOverflowSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'stackoverflow'</span></span><br><span class="line">    start_urls = [<span class="string">'http://stackoverflow.com/questions?sort=votes'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> href <span class="keyword">in</span> response.css(<span class="string">'.question-summary h3 a::attr(href)'</span>):</span><br><span class="line">            full_url = response.urljoin(href.extract())</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(full_url, callback=self.parse_question)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_question</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="keyword">yield</span> &#123;</span><br><span class="line">            <span class="string">'title'</span>: response.css(<span class="string">'h1 a::text'</span>).extract()[<span class="number">0</span>],</span><br><span class="line">            <span class="string">'votes'</span>: response.css(<span class="string">'.question .vote-count-post::text'</span>).extract()[<span class="number">0</span>],</span><br><span class="line">            <span class="string">'body'</span>: response.css(<span class="string">'.question .post-text'</span>).extract()[<span class="number">0</span>],</span><br><span class="line">            <span class="string">'tags'</span>: response.css(<span class="string">'.question .post-tag::text'</span>).extract(),</span><br><span class="line">            <span class="string">'link'</span>: response.url,</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure>
<p>运行：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy runspider stackoverflow_spider.py -o top-stackoverflow-questions.json</span><br></pre></td></tr></table></figure></p>
<p>结果类似下面：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[&#123;</span><br><span class="line">    &quot;body&quot;: &quot;... LONG HTML HERE ...&quot;,</span><br><span class="line">    &quot;link&quot;: &quot;http://stackoverflow.com/questions/11227809/why-is-processing-a-sorted-array-faster-than-an-unsorted-array&quot;,</span><br><span class="line">    &quot;tags&quot;: [&quot;java&quot;, &quot;c++&quot;, &quot;performance&quot;, &quot;optimization&quot;],</span><br><span class="line">    &quot;title&quot;: &quot;Why is processing a sorted array faster than an unsorted array?&quot;,</span><br><span class="line">    &quot;votes&quot;: &quot;9924&quot;</span><br><span class="line">&#125;,</span><br><span class="line">&#123;</span><br><span class="line">    &quot;body&quot;: &quot;... LONG HTML HERE ...&quot;,</span><br><span class="line">    &quot;link&quot;: &quot;http://stackoverflow.com/questions/1260748/how-do-i-remove-a-git-submodule&quot;,</span><br><span class="line">    &quot;tags&quot;: [&quot;git&quot;, &quot;git-submodules&quot;],</span><br><span class="line">    &quot;title&quot;: &quot;How do I remove a Git submodule?&quot;,</span><br><span class="line">    &quot;votes&quot;: &quot;1764&quot;</span><br><span class="line">&#125;,</span><br><span class="line">...]</span><br></pre></td></tr></table></figure></p>
<p>当你运行<code>scrapy runspider somefile.py</code>这条语句的时候，Scrapy会去寻找源文件中定义的一个spider并且交给爬虫引擎来执行它。<br><code>start_urls</code>属性定义了开始的URL，爬虫会通过它来构建初始的请求，返回response后再调用默认的回调方法<code>parse</code>并传入这个response。<br>我们在<code>parse</code>回调方法中通过使用css选择器提取每个提问页面链接的href属性值，然后<code>yield</code>另外一个请求，<br>并注册<code>parse_question</code>回调方法，在这个请求完成后被执行。</p>
<p>处理流程图：</p>
<p><img src="https://raw.githubusercontent.com/bbkali/picbad/master/2020-1-19-17-30-31" alt="2020-1-19-17-30-31"></p>
<p>Scrapy的一个好处是所有请求都是被调度并异步处理，就算某个请求出错也不影响其他请求继续被处理。</p>
<p>我们的示例中将解析结果生成json格式，你还可以导出为其他格式（比如XML、CSV），或者是将其存储到FTP、Amazon S3上。<br>你还可以通过<a href="http://doc.scrapy.org/en/1.0/topics/item-pipeline.html#topics-item-pipeline" target="_blank" rel="noopener">pipeline</a><br>将它们存储到数据库中去，这些数据保存的方式各种各样。</p>
<h2 id="Scrapy特性一览"><a href="#Scrapy特性一览" class="headerlink" title="Scrapy特性一览"></a>Scrapy特性一览</h2><p>你已经可以通过Scrapy从一个网站上面爬取数据并将其解析保存下来了，但是这只是Scrapy的皮毛。<br>Scrapy提供了更多的特性来让你爬取更加容易和高效。比如：</p>
<ol>
<li>内置支持扩展的CSS选择器和XPath表达式来从HTML/XML源码中选择并提取数据，还能使用正则表达式</li>
<li>提供交互式shell控制台试验CSS和XPath表达式，这个在调试你的蜘蛛程序时很有用</li>
<li>内置支持生成多种格式的订阅导出（JSON、CSV、XML）并将它们存储在多个位置（FTP、S3、本地文件系统）</li>
<li>健壮的编码支持和自动识别，用于处理外文、非标准和错误编码问题</li>
<li>可扩展，允许你使用<a href="http://doc.scrapy.org/en/1.0/topics/signals.html#topics-signals" target="_blank" rel="noopener">signals</a><br>和友好的API(middlewares, extensions, 和pipelines)来编写自定义插件功能。</li>
<li>大量的内置扩展和中间件供使用：<ul>
<li>cookies and session handling</li>
<li>HTTP features like compression, authentication, caching</li>
<li>user-agent spoofing</li>
<li>robots.txt</li>
<li>crawl depth restriction</li>
<li>and more</li>
</ul>
</li>
<li>还有其他好多好东东，比如可重复利用蜘蛛来爬取<a href="http://www.sitemaps.org/" target="_blank" rel="noopener">Sitemaps</a>和XML/CSV订阅，<br>一个跟爬取元素关联的媒体管道来<br><a href="http://doc.scrapy.org/en/1.0/topics/media-pipeline.html#topics-media-pipeline" target="_blank" rel="noopener">自动下载图片</a>，<br>一个缓存DNS解析器等等。</li>
</ol>
</div></div><a class="button-hover more" href="/2020/01/19/scrapy-入门篇/#more">阅读全文</a></div></div><div id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/"><i class="fas fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/16/">16</a><a class="extend next" rel="next" href="/page/3/"><i class="fas fa-angle-right"></i></a></div></div></div></div><div class="button-hover" id="return-top"><i class="fas fa-arrow-up" aria-hidden="true"></i></div><footer><div id="footer"><div class="button-hover" id="side-button"><i class="fas fa-arrow-right"></i></div><div class="right-content"><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_site_uv"><i class="fas fa-user"></i></span><span id="busuanzi_value_site_uv"></span><span></span><span class="footer-separator">|</span><span id="busuanzi_container_site_pv"><i class="fas fa-eye"></i></span><span id="busuanzi_value_site_pv"></span><span></span></div><div class="copyright">&copy;2019 ～ 2020 By bb</div></div></div></footer></div><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/thirdparty/jquery-3.3.1.min.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/thirdparty/velocity.min.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/thirdparty/jquery.mCustomScrollbar.concat.min.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/fan.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/canvas_bg.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/utils.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/scroll.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/sidebar.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/copy.js"></script><!--script(src=url)--><div class="search-dialog"><div id="algolia-search-title">Algolia</div><div class="search-close-button"><i class="fa fa-times"></i></div><!--div#current-refined-values--><!--div#clear-all--><div id="search-box"></div><!--div#refinement-list--><hr><div id="hits"></div><div id="algolia-pagination"></div></div><div class="search-mask"></div><script src="/js/search/algolia.js"></script></body></html>