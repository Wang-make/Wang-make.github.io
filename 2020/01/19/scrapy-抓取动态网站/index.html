<!DOCTYPE html><html><head><meta name="generator" content="Hexo 3.9.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="scrapy-抓取动态网站"><meta name="keywords" content="Scrapy"><meta name="author" content="bb,shuiyue75381@gmail.com"><meta name="copyright" content="bb"><title>scrapy-抓取动态网站【bb的博客】</title><link rel="stylesheet" href="/css/fan.css"><link rel="stylesheet" href="/css/thirdparty/jquery.mCustomScrollbar.min.css"><link rel="icon" href="/favicon.ico"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.10.4/dist/instantsearch.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.10.4/dist/instantsearch-theme-algolia.min.css"><script src="https://cdn.jsdelivr.net/npm/instantsearch.js@2.10.4"></script><!--link(rel="dns-prefetch" href="https://cdn.jsdelivr.net")--><!--link(rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.1.1/dist/instantsearch.min.css")--><!--script(src="https://cdn.jsdelivr.net/npm/instantsearch.js@2.1.1/dist/instantsearch.min.js" defer)--><script>var isPassword = '' || false;
if (isPassword) {
    if (prompt('请输入文章密码') !== '') {
        alert('密码错误！');
        history.back();
    }
}</script><script>window.GLOBAL_CONFIG = {
  root: '/',
  algolia: {"appId":"X7RY6NGU4G","apiKey":"bf7ed65264918bbc03f12b4cc1212d85","indexName":"myblog","hits":{"per_page":10},"languages":{"input_placeholder":"搜索文章","hits_empty":"找不到您查询的内容:${query}","hits_stats":"找到 ${hits} 条结果，用时 ${time} 毫秒"}},
  localSearch: undefined,
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  }
}</script></head><body><canvas id="universe"></canvas><!--#body--><div id="sidebar"><div class="toggle-sidebar-info button-hover"><span data-toggle="文章目录">站点概览</span></div><div class="sidebar-toc"><div class="sidebar-toc-title">目录</div><div class="sidebar-toc-progress"><span class="progress-notice">您已阅读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc-progress-bar"></div></div><div class="sidebar-toc-content" id="sidebar-toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Scrapy教程12-抓取动态网站"><span class="toc-number">1.</span> <span class="toc-text">Scrapy教程12- 抓取动态网站</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#scrapy-splash简介"><span class="toc-number">1.0.1.</span> <span class="toc-text">scrapy-splash简介</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#安装docker"><span class="toc-number">1.0.2.</span> <span class="toc-text">安装docker</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#安装Splash"><span class="toc-number">1.0.3.</span> <span class="toc-text">安装Splash</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#安装scrapy-splash"><span class="toc-number">1.0.4.</span> <span class="toc-text">安装scrapy-splash</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#配置scrapy-splash"><span class="toc-number">1.0.5.</span> <span class="toc-text">配置scrapy-splash</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#使用scrapy-splash"><span class="toc-number">1.0.6.</span> <span class="toc-text">使用scrapy-splash</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#SplashRequest"><span class="toc-number">1.0.6.1.</span> <span class="toc-text">SplashRequest</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Responses"><span class="toc-number">1.0.6.2.</span> <span class="toc-text">Responses</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Session的处理"><span class="toc-number">1.0.6.3.</span> <span class="toc-text">Session的处理</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#使用实例"><span class="toc-number">1.0.7.</span> <span class="toc-text">使用实例</span></a></li></ol></li></ol></div></div><div class="author-info hide"><div class="author-info-avatar"><img class="author-info-avatar-img" src="/avatar.png"></div><div class="author-info-name">bb</div><div class="author-info-description">This is myblog!</div><div class="links-buttons"><a class="links-button button-hover" href="https://github.com/bbkali" target="_blank">GitHub<i class="icon-dot bg-color1"></i></a><a class="links-button button-hover" href="mailto:shuiyue75381@gmail.com" target="_blank">E-Mail<i class="icon-dot bg-color9"></i></a><a class="links-button button-hover" href="tencent://message/?uin=1019593584&amp;Site=&amp;Menu=yes" target="_blank">QQ<i class="icon-dot bg-color8"></i></a></div><div class="author-info-articles"><a class="author-info-articles-archives article-meta" href="/archives"><span class="pull-top">日志</span><span class="pull-bottom">80</span></a><a class="author-info-articles-tags article-meta" href="/tags"><span class="pull-top">标签</span><span class="pull-bottom">65</span></a><a class="author-info-articles-categories article-meta" href="/categories"><span class="pull-top">分类</span><span class="pull-bottom">31</span></a></div></div></div><div id="main-container"><header><div id="menu-outer"><i class="menu-list-icon fas fa-bars"></i><nav id="menu-inner"><a class="menu-item" href="/">首页</a><a class="menu-item" href="/tags">标签</a><a class="menu-item" href="/categories">分类</a><a class="menu-item" href="/archives">归档</a><a class="menu-item" href="/about">关于</a></nav><div class="right-info"><a class="search social-icon"><i class="fas fa-search"></i><span> 搜索</span></a><a class="title-name" href="/">bb的博客</a><span id="now-time"></span></div></div></header><div id="content-outer"><div id="content-inner"><article id="post"><div class="post-header"><div class="title">scrapy-抓取动态网站</div><div class="container"><time class="button-hover post-date"><i class="fas fa-calendar-alt article-icon" aria-hidden="true"></i> 发表于 2020-01-19 | 更新于 2020-01-23</time><!--time.button-hover.post-date #[i.fas.fa-calendar-alt.article-icon(aria-hidden="true")] #[=__('post.modified')] #[=date(page['updated'], config.date_format)]--><div class="button-hover categories"><i class="fa fa-inbox article-icon" aria-hidden="true"></i><a class="link-a" href="/categories/Scrapy/">Scrapy</a></div><div class="button-hover tags"><i class="fa fa-tag article-icon" aria-hidden="true"></i><a class="link-a" href="/tags/Scrapy/">Scrapy</a></div></div></div><div class="main-content"><h1 id="Scrapy教程12-抓取动态网站"><a href="#Scrapy教程12-抓取动态网站" class="headerlink" title="Scrapy教程12- 抓取动态网站"></a>Scrapy教程12- 抓取动态网站</h1><p>前面我们介绍的都是去抓取静态的网站页面，也就是说我们打开某个链接，它的内容全部呈现出来。<br>但是如今的互联网大部分的web页面都是动态的，经常逛的网站例如京东、淘宝等，商品列表都是js，并有Ajax渲染，<br>下载某个链接得到的页面里面含有异步加载的内容，这样再使用之前的方式我们根本获取不到异步加载的这些网页内容。</p>
<p>使用Javascript渲染和处理网页是种非常常见的做法，如何处理一个大量使用Javascript的页面是Scrapy爬虫开发中一个常见的问题，<br>这篇文章将说明如何在Scrapy爬虫中使用<a href="https://github.com/scrapy-plugins/scrapy-splash" target="_blank" rel="noopener">scrapy-splash</a>来处理页面中得Javascript。</p>
<h3 id="scrapy-splash简介"><a href="#scrapy-splash简介" class="headerlink" title="scrapy-splash简介"></a>scrapy-splash简介</h3><p>scrapy-splash利用<a href="https://github.com/scrapy/scrapy" target="_blank" rel="noopener">Splash</a>将javascript和Scrapy集成起来，使得Scrapy可以抓取动态网页。</p>
<p>Splash是一个javascript渲染服务，是实现了HTTP API的轻量级浏览器，底层基于Twisted和QT框架，Python语言编写。所以首先你得安装Splash实例<br><a id="more"></a></p>
<h3 id="安装docker"><a href="#安装docker" class="headerlink" title="安装docker"></a>安装docker</h3><p>官网建议使用docker容器安装方式Splash。那么首先你得先安装docker</p>
<p>参考<a href="https://docs.docker.com/engine/installation/linux/ubuntulinux/" target="_blank" rel="noopener">官方安装文档</a>，这里我选择Ubuntu 12.04 LTS版本安装</p>
<p>升级内核版本，docker需要3.13内核<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get update</span><br><span class="line">$ sudo apt-get install linux-image-generic-lts-trusty</span><br><span class="line">$ sudo reboot</span><br></pre></td></tr></table></figure></p>
<p>安装<code>CA</code>认证<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get install apt-transport-https ca-certificates</span><br></pre></td></tr></table></figure></p>
<p>增加新的<code>GPG</code>key<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-key adv --keyserver hkp://p80.pool.sks-keyservers.net:80 --recv-keys 58118E89F3A912897C070ADBF76221572C52609D</span><br></pre></td></tr></table></figure></p>
<p>打开<code>/etc/apt/sources.list.d/docker.list</code>，如果没有就创建一个，然后删除任何已存在的内容，再增加下面一句<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">deb https://apt.dockerproject.org/repo ubuntu-precise main</span><br></pre></td></tr></table></figure></p>
<p>更新APT<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get update</span><br><span class="line">$ sudo apt-get purge lxc-docker</span><br><span class="line">$ apt-cache policy docker-engine</span><br></pre></td></tr></table></figure></p>
<p>安装<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get install docker-engine</span><br></pre></td></tr></table></figure></p>
<p>启动docker服务<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo service docker start</span><br></pre></td></tr></table></figure></p>
<p>验证是否启动成功<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker run hello-world</span><br></pre></td></tr></table></figure></p>
<p>上面这条命令会下载一个测试镜像并在容器中运行它，它会打印一个消息，然后退出。</p>
<h3 id="安装Splash"><a href="#安装Splash" class="headerlink" title="安装Splash"></a>安装Splash</h3><p>拉取镜像下来<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker pull scrapinghub/splash</span><br></pre></td></tr></table></figure></p>
<p>启动容器<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker run -p 5023:5023 -p 8050:8050 -p 8051:8051 scrapinghub/splash</span><br></pre></td></tr></table></figure></p>
<p>现在可以通过0.0.0.0:8050(http),8051(https),5023 (telnet)来访问Splash了。</p>
<h3 id="安装scrapy-splash"><a href="#安装scrapy-splash" class="headerlink" title="安装scrapy-splash"></a>安装scrapy-splash</h3><p>使用pip安装<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ pip install scrapy-splash</span><br></pre></td></tr></table></figure></p>
<h3 id="配置scrapy-splash"><a href="#配置scrapy-splash" class="headerlink" title="配置scrapy-splash"></a>配置scrapy-splash</h3><p>在你的scrapy工程的配置文件<code>settings.py</code>中添加<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SPLASH_URL = <span class="string">'http://192.168.203.92:8050'</span></span><br></pre></td></tr></table></figure></p>
<p>添加Splash中间件，还是在<code>settings.py</code>中通过<code>DOWNLOADER_MIDDLEWARES</code>指定，并且修改<code>HttpCompressionMiddleware</code>的优先级<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">DOWNLOADER_MIDDLEWARES = &#123;</span><br><span class="line">    <span class="string">'scrapy_splash.SplashCookiesMiddleware'</span>: <span class="number">723</span>,</span><br><span class="line">    <span class="string">'scrapy_splash.SplashMiddleware'</span>: <span class="number">725</span>,</span><br><span class="line">    <span class="string">'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware'</span>: <span class="number">810</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>默认情况下，HttpProxyMiddleware的优先级是750，要把它放在Splash中间件后面</p>
<p>设置Splash自己的去重过滤器<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DUPEFILTER_CLASS = <span class="string">'scrapy_splash.SplashAwareDupeFilter'</span></span><br></pre></td></tr></table></figure></p>
<p>如果你使用Splash的Http缓存，那么还要指定一个自定义的缓存后台存储介质，scrapy-splash提供了一个<code>scrapy.contrib.httpcache.FilesystemCacheStorage</code>的子类<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HTTPCACHE_STORAGE = <span class="string">'scrapy_splash.SplashAwareFSCacheStorage'</span></span><br></pre></td></tr></table></figure></p>
<p>如果你要使用其他的缓存存储，那么需要继承这个类并且将所有的<code>scrapy.util.request.request_fingerprint</code>调用替换成<code>scrapy_splash.splash_request_fingerprint</code></p>
<h3 id="使用scrapy-splash"><a href="#使用scrapy-splash" class="headerlink" title="使用scrapy-splash"></a>使用scrapy-splash</h3><h4 id="SplashRequest"><a href="#SplashRequest" class="headerlink" title="SplashRequest"></a>SplashRequest</h4><p>最简单的渲染请求的方式是使用<code>scrapy_splash.SplashRequest</code>，通常你应该选择使用这个<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">yield</span> SplashRequest(url, self.parse_result,</span><br><span class="line">    args=&#123;</span><br><span class="line">        <span class="comment"># optional; parameters passed to Splash HTTP API</span></span><br><span class="line">        <span class="string">'wait'</span>: <span class="number">0.5</span>,</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 'url' is prefilled from request url</span></span><br><span class="line">        <span class="comment"># 'http_method' is set to 'POST' for POST requests</span></span><br><span class="line">        <span class="comment"># 'body' is set to request body for POST requests</span></span><br><span class="line">    &#125;,</span><br><span class="line">    endpoint=<span class="string">'render.json'</span>, <span class="comment"># optional; default is render.html</span></span><br><span class="line">    splash_url=<span class="string">'&lt;url&gt;'</span>,     <span class="comment"># optional; overrides SPLASH_URL</span></span><br><span class="line">    slot_policy=scrapy_splash.SlotPolicy.PER_DOMAIN,  <span class="comment"># optional</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></p>
<p>另外，你还可以在普通的scrapy请求中传递<code>splash</code>请求meta关键字达到同样的效果<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">yield</span> scrapy.Request(url, self.parse_result, meta=&#123;</span><br><span class="line">    <span class="string">'splash'</span>: &#123;</span><br><span class="line">        <span class="string">'args'</span>: &#123;</span><br><span class="line">            <span class="comment"># set rendering arguments here</span></span><br><span class="line">            <span class="string">'html'</span>: <span class="number">1</span>,</span><br><span class="line">            <span class="string">'png'</span>: <span class="number">1</span>,</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 'url' is prefilled from request url</span></span><br><span class="line">            <span class="comment"># 'http_method' is set to 'POST' for POST requests</span></span><br><span class="line">            <span class="comment"># 'body' is set to request body for POST requests</span></span><br><span class="line">        &#125;,</span><br><span class="line"></span><br><span class="line">        <span class="comment"># optional parameters</span></span><br><span class="line">        <span class="string">'endpoint'</span>: <span class="string">'render.json'</span>,  <span class="comment"># optional; default is render.json</span></span><br><span class="line">        <span class="string">'splash_url'</span>: <span class="string">'&lt;url&gt;'</span>,      <span class="comment"># optional; overrides SPLASH_URL</span></span><br><span class="line">        <span class="string">'slot_policy'</span>: scrapy_splash.SlotPolicy.PER_DOMAIN,</span><br><span class="line">        <span class="string">'splash_headers'</span>: &#123;&#125;,       <span class="comment"># optional; a dict with headers sent to Splash</span></span><br><span class="line">        <span class="string">'dont_process_response'</span>: <span class="literal">True</span>, <span class="comment"># optional, default is False</span></span><br><span class="line">        <span class="string">'dont_send_headers'</span>: <span class="literal">True</span>,  <span class="comment"># optional, default is False</span></span><br><span class="line">        <span class="string">'magic_response'</span>: <span class="literal">False</span>,    <span class="comment"># optional, default is True</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure></p>
<p>Splash API说明，使用<code>SplashRequest</code>是一个非常便利的工具来填充<code>request.meta[&#39;splash&#39;]</code>里的数据</p>
<ul>
<li>meta[‘splash’][‘args’] 包含了发往Splash的参数。</li>
<li>meta[‘splash’][‘endpoint’] 指定了Splash所使用的endpoint，默认是<a href="http://splash.readthedocs.org/en/latest/api.html#render-html" target="_blank" rel="noopener">render.html</a></li>
<li>meta[‘splash’][‘splash_url’] 覆盖了<code>settings.py</code>文件中配置的Splash URL</li>
<li>meta[‘splash’][‘splash_headers’] 运行你增加或修改发往Splash服务器的HTTP头部信息，注意这个不是修改发往远程web站点的HTTP头部</li>
<li>meta[‘splash’][‘dont_send_headers’] 如果你不想传递headers给Splash，将它设置成True</li>
<li>meta[‘splash’][‘slot_policy’] 让你自定义Splash请求的同步设置</li>
<li>meta[‘splash’][‘dont_process_response’] 当你设置成True后，<code>SplashMiddleware</code>不会修改默认的<code>scrapy.Response</code>请求。默认是会返回<code>SplashResponse</code>子类响应比如<code>SplashTextResponse</code></li>
<li>meta[‘splash’][‘magic_response’] 默认为True，Splash会自动设置Response的一些属性，比如<code>response.headers</code>,<code>response.body</code>等</li>
</ul>
<p>如果你想通过Splash来提交Form请求，可以使用<code>scrapy_splash.SplashFormRequest</code>，它跟<code>SplashRequest</code>使用是一样的。</p>
<h4 id="Responses"><a href="#Responses" class="headerlink" title="Responses"></a>Responses</h4><p>对于不同的Splash请求，scrapy-splash返回不同的Response子类</p>
<ul>
<li>SplashResponse 二进制响应，比如对/render.png的响应</li>
<li>SplashTextResponse 文本响应，比如对/render.html的响应</li>
<li>SplashJsonResponse JSON响应，比如对/render.json或使用Lua脚本的/execute的响应</li>
</ul>
<p>如果你只想使用标准的Response对象，就设置<code>meta[&#39;splash&#39;][&#39;dont_process_response&#39;]=True</code></p>
<p>所有这些Response会把<code>response.url</code>设置成原始请求URL(也就是你要渲染的页面URL)，而不是Splash endpoint的URL地址。实际地址通过<code>response.real_url</code>得到</p>
<h4 id="Session的处理"><a href="#Session的处理" class="headerlink" title="Session的处理"></a>Session的处理</h4><p>Splash本身是无状态的，那么为了支持scrapy-splash的session必须编写Lua脚本，使用<code>/execute</code><br><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">main</span><span class="params">(splash)</span></span></span><br><span class="line">    splash:init_cookies(splash.args.cookies)</span><br><span class="line"></span><br><span class="line">    <span class="comment">-- ... your script</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        cookies = splash:get_cookies(),</span><br><span class="line">        <span class="comment">-- ... other results, e.g. html</span></span><br><span class="line">    &#125;</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure></p>
<p>而标准的scrapy session参数可以使用<code>SplashRequest</code>将cookie添加到当前Splash cookiejar中</p>
<h3 id="使用实例"><a href="#使用实例" class="headerlink" title="使用实例"></a>使用实例</h3><p>接下来我通过一个实际的例子来演示怎样使用，我选择爬取<a href="http://www.jd.com/" target="_blank" rel="noopener">京东网</a>首页的异步加载内容。</p>
<p>京东网打开首页的时候只会将导航菜单加载出来，其他具体首页内容都是异步加载的，下面有个”猜你喜欢”这个内容也是异步加载的，<br>我现在就通过爬取这个”猜你喜欢”这四个字来说明下普通的Scrapy爬取和通过使用了Splash加载异步内容的区别。</p>
<p>首先我们写个简单的测试Spider，不使用splash：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TestSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">"test"</span></span><br><span class="line">    allowed_domains = [<span class="string">"jd.com"</span>]</span><br><span class="line">    start_urls = [</span><br><span class="line">        <span class="string">"http://www.jd.com/"</span></span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        logging.info(<span class="string">u'---------我这个是简单的直接获取京东网首页测试---------'</span>)</span><br><span class="line">        guessyou = response.xpath(<span class="string">'//div[@id="guessyou"]/div[1]/h2/text()'</span>).extract_first()</span><br><span class="line">        logging.info(<span class="string">u"find：%s"</span> % guessyou)</span><br><span class="line">        logging.info(<span class="string">u'---------------success----------------'</span>)</span><br></pre></td></tr></table></figure></p>
<p>然后运行结果：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">2016-04-18 14:42:44 test_spider.py[line:20] INFO ---------我这个是简单的直接获取京东网首页测试---------</span><br><span class="line">2016-04-18 14:42:44 test_spider.py[line:22] INFO find：None</span><br><span class="line">2016-04-18 14:42:44 test_spider.py[line:23] INFO ---------------success----------------</span><br></pre></td></tr></table></figure></p>
<p>我找不到那个”猜你喜欢”这四个字</p>
<p>接下来我使用splash来爬取<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> scrapy_splash <span class="keyword">import</span> SplashRequest</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">JsSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">"jd"</span></span><br><span class="line">    allowed_domains = [<span class="string">"jd.com"</span>]</span><br><span class="line">    start_urls = [</span><br><span class="line">        <span class="string">"http://www.jd.com/"</span></span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start_requests</span><span class="params">(self)</span>:</span></span><br><span class="line">        splash_args = &#123;</span><br><span class="line">            <span class="string">'wait'</span>: <span class="number">0.5</span>,</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span> url <span class="keyword">in</span> self.start_urls:</span><br><span class="line">            <span class="keyword">yield</span> SplashRequest(url, self.parse_result, endpoint=<span class="string">'render.html'</span>,</span><br><span class="line">                                args=splash_args)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_result</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        logging.info(<span class="string">u'----------使用splash爬取京东网首页异步加载内容-----------'</span>)</span><br><span class="line">        guessyou = response.xpath(<span class="string">'//div[@id="guessyou"]/div[1]/h2/text()'</span>).extract_first()</span><br><span class="line">        logging.info(<span class="string">u"find：%s"</span> % guessyou)</span><br><span class="line">        logging.info(<span class="string">u'---------------success----------------'</span>)</span><br></pre></td></tr></table></figure></p>
<p>运行结果：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">2016-04-18 14:42:51 js_spider.py[line:36] INFO ----------使用splash爬取京东网首页异步加载内容-----------</span><br><span class="line">2016-04-18 14:42:51 js_spider.py[line:38] INFO find：猜你喜欢</span><br><span class="line">2016-04-18 14:42:51 js_spider.py[line:39] INFO ---------------success----------------</span><br></pre></td></tr></table></figure></p>
<p>可以看出结果里面已经找到了这个”猜你喜欢”，说明异步加载内容爬取成功！</p>
</div><div class="post-copyright"><div class="post-copyright-author"><span class="post-copyright-meta">本文作者: </span><span class="post-copyright-info"><a href="mailto:shuiyue75381@gmail.com">bb</a></span></div><div class="post-copyright-type"><span class="post-copyright-meta">本文链接: </span><span class="post-copyright-info"><a href="http://bbkali.github.io/2020/01/19/scrapy-抓取动态网站/">http://bbkali.github.io/2020/01/19/scrapy-抓取动态网站/</a></span></div><div class="post-copyright-notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://bbkali.github.io">bb的博客</a>！</span></div></div></article><div id="pagination"><div class="prev-post pull-left"><span class="line line-top"></span><span class="line line-right"></span><span class="line line-bottom"></span><span class="line line-left"></span><a href="/2020/01/19/scrapy-Item Pipeline/"><i class="fas fa-angle-left">&nbsp;</i><span>scrapy-Item Pipeline</span></a></div><div class="next-post pull-right"><span class="line line-top"></span><span class="line line-right"></span><span class="line line-bottom"></span><span class="line line-left"></span><a href="/2020/01/19/scrapy-文件与图片/"><span>scrapy-文件与图片</span><span>&nbsp;</span><i class="fas fa-angle-right"></i></a></div></div><!--div!= paginator()--></div></div><div class="button-hover" id="return-top"><i class="fas fa-arrow-up" aria-hidden="true"></i></div><footer><div id="footer"><div class="button-hover" id="side-button"><i class="fas fa-arrow-right"></i></div><div class="right-content"><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fas fa-file-o"></i></span><span id="busuanzi_value_page_pv"></span><span></span></div><div class="copyright">&copy;2019 ～ 2020 By bb</div></div></div></footer></div><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/thirdparty/jquery-3.3.1.min.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/thirdparty/velocity.min.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/thirdparty/jquery.mCustomScrollbar.concat.min.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/fan.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/canvas_bg.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/utils.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/scroll.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/sidebar.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/copy.js"></script><!--script(src=url)--><div class="search-dialog"><div id="algolia-search-title">Algolia</div><div class="search-close-button"><i class="fa fa-times"></i></div><!--div#current-refined-values--><!--div#clear-all--><div id="search-box"></div><!--div#refinement-list--><hr><div id="hits"></div><div id="algolia-pagination"></div></div><div class="search-mask"></div><script src="/js/search/algolia.js"></script></body></html>